{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07917f7d",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression Simulation\n",
    "\n",
    "This notebook simulates binary data, fits Bayesian logistic regression, and summarizes posterior inference for $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38f0b8",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "For $i=1,\\ldots,n$, let $y_i\\in\\{0,1\\}$ and $x_i\\in\\mathbb{R}^p$.\n",
    "\n",
    "$$\n",
    "\\Pr(y_i=1\\mid x_i,\\theta)=\\sigma(x_i'\\theta),\\qquad \\sigma(t)=\\frac{1}{1+e^{-t}}.\n",
    "$$\n",
    "\n",
    "The likelihood is\n",
    "$$\n",
    "p(y\\mid\\theta)=\\prod_{i=1}^n \\sigma(x_i'\\theta)^{y_i}\\left[1-\\sigma(x_i'\\theta)\\right]^{1-y_i}.\n",
    "$$\n",
    "\n",
    "We use a Gaussian prior:\n",
    "$$\n",
    "\\theta\\sim N(0,\\tau^2I_p).\n",
    "$$\n",
    "\n",
    "The posterior is proportional to\n",
    "$$\n",
    "p(\\theta\\mid y)\\propto p(y\\mid\\theta)\\,p(\\theta).\n",
    "$$\n",
    "\n",
    "Sampling is done with `emcee` using a Gaussian Metropolis-Hastings proposal (`emcee.moves.GaussianMove`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dc3574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:15:37.054864Z",
     "iopub.status.busy": "2026-02-22T15:15:37.054864Z",
     "iopub.status.idle": "2026-02-22T15:15:37.717449Z",
     "shell.execute_reply": "2026-02-22T15:15:37.717449Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0e505c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:15:37.719758Z",
     "iopub.status.busy": "2026-02-22T15:15:37.719758Z",
     "iopub.status.idle": "2026-02-22T15:15:37.725828Z",
     "shell.execute_reply": "2026-02-22T15:15:37.725828Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_logistic_data(n_obs, beta_true, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x1 = rng.normal(size=n_obs)\n",
    "    x2 = rng.normal(size=n_obs)\n",
    "    X = np.column_stack([np.ones(n_obs), x1, x2])\n",
    "    eta = X @ beta_true\n",
    "    p = 1.0 / (1.0 + np.exp(-eta))\n",
    "    y = rng.binomial(1, p, size=n_obs)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def log_prior(theta, prior_sd):\n",
    "    if not np.all(np.isfinite(theta)):\n",
    "        return -np.inf\n",
    "    return -0.5 * np.sum((theta / prior_sd) ** 2)\n",
    "\n",
    "\n",
    "def log_likelihood(theta, X, y):\n",
    "    eta = X @ theta\n",
    "    return np.sum(y * eta - np.logaddexp(0.0, eta))\n",
    "\n",
    "\n",
    "def log_posterior(theta, X, y, prior_sd):\n",
    "    lp = log_prior(theta, prior_sd)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, X, y)\n",
    "\n",
    "\n",
    "def run_mcmc(X, y, prior_sd, seed, n_walkers, burn_in, n_steps, thin, proposal_scale):\n",
    "    rng = np.random.default_rng(seed + 1)\n",
    "    n_dim = X.shape[1]\n",
    "    if n_walkers < 2 * n_dim:\n",
    "        raise ValueError(f\"n_walkers must be at least {2 * n_dim}.\")\n",
    "\n",
    "    initial = rng.normal(0.0, 0.2, size=(n_walkers, n_dim))\n",
    "    mh_move = emcee.moves.GaussianMove(cov=(proposal_scale**2) * np.eye(n_dim), mode=\"vector\")\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nwalkers=n_walkers,\n",
    "        ndim=n_dim,\n",
    "        log_prob_fn=log_posterior,\n",
    "        args=(X, y, prior_sd),\n",
    "        moves=mh_move,\n",
    "    )\n",
    "\n",
    "    state = sampler.run_mcmc(initial, burn_in, progress=False)\n",
    "    sampler.reset()\n",
    "    sampler.run_mcmc(state, n_steps, progress=False)\n",
    "    samples = sampler.get_chain(flat=True, thin=thin)\n",
    "    accept_rate = float(np.mean(sampler.acceptance_fraction))\n",
    "    return samples, accept_rate\n",
    "\n",
    "\n",
    "def summarize(samples):\n",
    "    post_mean = np.mean(samples, axis=0)\n",
    "    ci_low = np.quantile(samples, 0.025, axis=0)\n",
    "    ci_high = np.quantile(samples, 0.975, axis=0)\n",
    "    return post_mean, ci_low, ci_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6e9cd",
   "metadata": {},
   "source": [
    "## Simulation Design\n",
    "\n",
    "True parameter: $\\theta_0 = (-0.4,\\;1.1,\\;-1.6)'$.\n",
    "\n",
    "MCMC settings below are chosen to run quickly while still giving stable posterior summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea23706b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:15:37.727908Z",
     "iopub.status.busy": "2026-02-22T15:15:37.727908Z",
     "iopub.status.idle": "2026-02-22T15:15:37.730822Z",
     "shell.execute_reply": "2026-02-22T15:15:37.730822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs=1000, mean(y)=0.458\n"
     ]
    }
   ],
   "source": [
    "seed = 2026\n",
    "n_obs = 1000\n",
    "beta_true = np.array([-0.4, 1.1, -1.6])\n",
    "prior_sd = 2.5\n",
    "n_walkers = 40\n",
    "burn_in = 1200\n",
    "n_steps = 2200\n",
    "thin = 5\n",
    "proposal_scale = 0.08\n",
    "\n",
    "X, y = simulate_logistic_data(n_obs=n_obs, beta_true=beta_true, seed=seed)\n",
    "print(f\"n_obs={n_obs}, mean(y)={y.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404625f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:15:37.732842Z",
     "iopub.status.busy": "2026-02-22T15:15:37.731839Z",
     "iopub.status.idle": "2026-02-22T15:15:42.114936Z",
     "shell.execute_reply": "2026-02-22T15:15:42.114936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acceptance fraction: 0.495\n",
      "name      true      post_mean    2.5%       97.5%\n",
      "intercept   -0.400      -0.418    -0.580    -0.261\n",
      "beta_1       1.100       1.032     0.851     1.222\n",
      "beta_2      -1.600      -1.634    -1.849    -1.422\n"
     ]
    }
   ],
   "source": [
    "samples, accept_rate = run_mcmc(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    prior_sd=prior_sd,\n",
    "    seed=seed,\n",
    "    n_walkers=n_walkers,\n",
    "    burn_in=burn_in,\n",
    "    n_steps=n_steps,\n",
    "    thin=thin,\n",
    "    proposal_scale=proposal_scale,\n",
    ")\n",
    "\n",
    "post_mean, ci_low, ci_high = summarize(samples)\n",
    "names = [\"intercept\", \"beta_1\", \"beta_2\"]\n",
    "\n",
    "print(f\"Mean acceptance fraction: {accept_rate:.3f}\")\n",
    "print(\"name      true      post_mean    2.5%       97.5%\")\n",
    "for i, name in enumerate(names):\n",
    "    print(f\"{name:9s} {beta_true[i]:8.3f} {post_mean[i]:11.3f} {ci_low[i]:9.3f} {ci_high[i]:9.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f81943",
   "metadata": {},
   "source": [
    "## Prediction Exercise (Posterior Predictive)\n",
    "\n",
    "Using posterior draws $\\{\\theta^{(s)}\\}_{s=1}^S$, the posterior predictive probability for a new feature vector $\\tilde x$ is\n",
    "$$\n",
    "\\Pr(\\tilde y=1\\mid \\tilde x, y) \\approx \\frac{1}{S}\\sum_{s=1}^S \\sigma(\\tilde x'\\theta^{(s)}).\n",
    "$$\n",
    "\n",
    "Below we evaluate prediction on a simulated holdout sample and report both point performance and posterior predictive intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c2d9ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T15:15:42.117427Z",
     "iopub.status.busy": "2026-02-22T15:15:42.117427Z",
     "iopub.status.idle": "2026-02-22T15:15:42.328057Z",
     "shell.execute_reply": "2026-02-22T15:15:42.327726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (threshold 0.5): 0.793\n",
      "Test log loss: 0.404\n",
      "\n",
      "First 5 posterior predictive probabilities with 95% intervals:\n",
      "obs   y_test   p_mean    p_2.5%    p_97.5%\n",
      "  0        0    0.072     0.052     0.096\n",
      "  1        0    0.021     0.013     0.033\n",
      "  2        1    0.864     0.826     0.897\n",
      "  3        0    0.079     0.058     0.105\n",
      "  4        1    0.653     0.605     0.699\n"
     ]
    }
   ],
   "source": [
    "# Holdout data from the same DGP\n",
    "n_test = 300\n",
    "X_test, y_test = simulate_logistic_data(n_obs=n_test, beta_true=beta_true, seed=seed + 100)\n",
    "\n",
    "# Posterior predictive probabilities for each test observation\n",
    "eta_draws = samples @ X_test.T                      # shape: (S, n_test)\n",
    "pred_draws = 1.0 / (1.0 + np.exp(-eta_draws))      # shape: (S, n_test)\n",
    "pred_mean = pred_draws.mean(axis=0)\n",
    "pred_low = np.quantile(pred_draws, 0.025, axis=0)\n",
    "pred_high = np.quantile(pred_draws, 0.975, axis=0)\n",
    "\n",
    "# Classification metrics based on posterior mean probability\n",
    "y_hat = (pred_mean >= 0.5).astype(int)\n",
    "accuracy = np.mean(y_hat == y_test)\n",
    "eps = 1e-12\n",
    "log_loss = -np.mean(y_test * np.log(pred_mean + eps) + (1 - y_test) * np.log(1 - pred_mean + eps))\n",
    "\n",
    "print(f\"Test accuracy (threshold 0.5): {accuracy:.3f}\")\n",
    "print(f\"Test log loss: {log_loss:.3f}\")\n",
    "print(\"\")\n",
    "print(\"First 5 posterior predictive probabilities with 95% intervals:\")\n",
    "print(\"obs   y_test   p_mean    p_2.5%    p_97.5%\")\n",
    "for i in range(5):\n",
    "    print(f\"{i:3d}   {y_test[i]:6d}   {pred_mean[i]:6.3f}   {pred_low[i]:7.3f}   {pred_high[i]:7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8f35e",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "- Posterior means should be close to true values in repeated simulations.\n",
    "- The 95% credible intervals should typically include the true coefficients at this sample size.\n",
    "- The acceptance fraction can be tuned with `proposal_scale`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
